import json
from faker import Faker
from datetime import datetime, timezone
import random

# Initialize Faker
fake = Faker()

# Generate new log entry
new_entry = {
    "timestamp": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%S.%fZ"),
    "service":  "log-sla-service",
    "status": random.choice(["healthy", "degraded", "down"])
}

# Convert to compact JSON format (one-line JSON)
compact_json = json.dumps(new_entry, separators=(",", ":"))

# Append to file
with open("app_sla.log", "a") as file:
    file.write(compact_json + "\n")

print(f"New log entry added: {compact_json}")


###
   filelog:
    include: [ "app_sla.log" ]  # Update with the actual file path
    start_at: beginning
    operators:
      - type: json_parser
        id: parse_json
        parse_from: body
        timestamp:
          parse_from: attributes.timestamp
          layout: '%Y-%m-%dT%H:%M:%S.%fZ'  # Adjust format based on your timestamp
          location: UTC
      - type: move
        from: attributes.timestamp
        to: attributes.collector_timestamp

  transform:
    log_statements:
      - context: log
        statements:
          - set(log.attributes["gateway_timestamp"], log.time)
        conditions:
          - attributes["service"] == "log-sla-service"


###
from(bucket: "your_bucket")
  |> range(start: -1h)  // Adjust time range as needed
  |> filter(fn: (r) => r["_measurement"] == "your_measurement")
  |> map(fn: (r) => ({
      _time: r["_time"],  
      collector_latency: float(v: int(v: time(v: r["collector_timestamp"])) - int(v: time(v: r["_time"]))) / 1000000000.0, 
      gateway_latency: float(v: int(v: time(v: r["gateway_timestamp"])) - int(v: time(v: r["collector_timestamp"]))) / 1000000000.0, 
      total_latency: float(v: int(v: time(v: r["gateway_timestamp"])) - int(v: time(v: r["_time"]))) / 1000000000.0
  }))


###
{job="otel-gateway"} 
| json  
| unwrap collector_timestamp as c_ts
| unwrap gateway_timestamp as g_ts
| unwrap log_stored_timestamp as s_ts
| __time(c_ts) as c_time
| __time(g_ts) as g_time
| __time(s_ts) as s_time
| delta = g_time - c_time
| store_delta = s_time - g_time
| line_format "Collector to Gateway Delay: {{ .delta }}s, Gateway to Storage Delay: {{ .store_delta }}s"

###
{job="otel-gateway"} 
| regexp "(?P<c_ts>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z) (?P<g_ts>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z) (?P<s_ts>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z)"
| duration(c_ts) as c_time
| duration(g_ts) as g_time
| duration(s_ts) as s_time
| delta = g_time - c_time
| store_delta = s_time - g_time
| line_format "Collector to Gateway Delay: {{ .delta }}s, Gateway to Storage Delay: {{ .store_delta }}s"


###
{service_name="unknown_service"} 
| json collector_timestamp, gateway_timestamp
| __time_from_timestamp(collector_timestamp) as c_time
| __time_from_timestamp(gateway_timestamp) as g_time
| timestamp() as stored_time  # Gets Loki ingestion timestamp
| delta_cg = g_time - c_time   # Collector → Gateway delay
| delta_gs = stored_time - g_time  # Gateway → Loki ingestion delay
| line_format "Collector to Gateway: {{ .delta_cg }}s, Gateway to Loki: {{ .delta_gs }}s"


##
{job="otel-gateway"} 
| json 
| duration(collector_timestamp) as c_time
| duration(gateway_timestamp) as g_time
| duration(log_stored_timestamp) as s_time
| delta = g_time - c_time
| store_delta = s_time - g_time
| line_format "Collector to Gateway Delay: {{ .delta }}s, Gateway to Storage Delay: {{ .store_delta }}s"

##

{service_name="unknown_service"} 
| json collector_timestamp, gateway_timestamp
| timestamp() as stored_time  # Loki ingestion time
| duration(collector_timestamp) as c_time
| duration(gateway_timestamp) as g_time
| delta_cg = g_time - c_time  # Collector → Gateway delay
| delta_gs = stored_time - g_time  # Gateway → Loki delay
| line_format "Collector to Gateway: {{ .delta_cg }}s, Gateway to Loki: {{ .delta_gs }}s"
